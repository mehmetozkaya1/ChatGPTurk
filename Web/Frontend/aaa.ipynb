{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (4.42.4)\n",
      "Requirement already satisfied: datasets in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from transformers) (0.24.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from transformers) (2.32.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from requests->transformers) (2024.7.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from pandas->datasets) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: accelerate in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (0.32.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.17 in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from accelerate) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from accelerate) (24.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from accelerate) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from accelerate) (2.3.1)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from accelerate) (0.24.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from torch>=1.10.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from torch>=1.10.0->accelerate) (2024.5.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from torch>=1.10.0->accelerate) (2021.4.0)\n",
      "Requirement already satisfied: requests in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from huggingface-hub->accelerate) (2.32.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from huggingface-hub->accelerate) (4.66.4)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.10.0->accelerate) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.10.0->accelerate) (2021.13.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2024.7.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\mehme\\anaconda3\\envs\\ml-dl\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "pip 24.1.2 from c:\\Users\\mehme\\anaconda3\\envs\\ML-DL\\Lib\\site-packages\\pip (python 3.11)\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers datasets\n",
    "%pip install accelerate\n",
    "%pip --version accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Description': 'Q. What does abutment of the nerve root mean?',\n",
       " 'Patient': 'Hi doctor,I am just wondering what is abutting and abutment of the nerve root means in a back issue. Please explain. What treatment is required for\\xa0annular bulging and tear?',\n",
       " 'Doctor': 'Hi. I have gone through your query with diligence and would like you to know that I am here to help you. For further information consult a neurologist online -->'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "# JSON dosyanızın yolunu belirtin\n",
    "dataset = load_dataset('ruslanmv/ai-medical-chatbot', 'default', split=\"train[:100000]\")\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Tokenizer'ı yükleyin\n",
    "tokenizer = AutoTokenizer.from_pretrained('t5-small')\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    # Girdiyi tokenize edin\n",
    "    encodings = tokenizer(examples['Patient'], padding='max_length', truncation=True, max_length=128)\n",
    "\n",
    "    # Yanıtı tokenize edin ve labels olarak ekleyin\n",
    "    encodings['labels'] = tokenizer(examples['Doctor'], padding='max_length', truncation=True, max_length=128)['input_ids']\n",
    "\n",
    "    return encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 100000/100000 [00:14<00:00, 6959.92 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "# Veri setini train ve test setlerine ayırma\n",
    "split_dataset = tokenized_dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "# DatasetDict oluşturma\n",
    "dataset_dict = DatasetDict({\n",
    "    'train': split_dataset['train'],\n",
    "    'test': split_dataset['test']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mehme\\anaconda3\\envs\\ML-DL\\Lib\\site-packages\\transformers\\training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "  2%|▎         | 500/20000 [00:49<37:31,  8.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.4388, 'grad_norm': 1.7864558696746826, 'learning_rate': 1.95e-05, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1000/20000 [01:41<38:47,  8.16it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.3327, 'grad_norm': 1.412244439125061, 'learning_rate': 1.9e-05, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1500/20000 [02:42<33:49,  9.12it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.2154, 'grad_norm': 1.4459115266799927, 'learning_rate': 1.8500000000000002e-05, 'epoch': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2000/20000 [03:40<23:09, 12.95it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.1096, 'grad_norm': 1.237950086593628, 'learning_rate': 1.8e-05, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 2500/20000 [04:35<40:36,  7.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.0591, 'grad_norm': 1.186504602432251, 'learning_rate': 1.7500000000000002e-05, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3000/20000 [05:36<37:54,  7.47it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.0015, 'grad_norm': 2.8916430473327637, 'learning_rate': 1.7e-05, 'epoch': 0.15}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 3500/20000 [06:37<34:00,  8.09it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9992, 'grad_norm': 1.2238351106643677, 'learning_rate': 1.65e-05, 'epoch': 0.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4000/20000 [07:36<31:59,  8.33it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9852, 'grad_norm': 1.3924503326416016, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▎       | 4500/20000 [08:39<31:07,  8.30it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.9377, 'grad_norm': 1.6365787982940674, 'learning_rate': 1.55e-05, 'epoch': 0.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5000/20000 [09:44<30:27,  8.21it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.8891, 'grad_norm': 2.182791233062744, 'learning_rate': 1.5000000000000002e-05, 'epoch': 0.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 5500/20000 [10:48<27:20,  8.84it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.871, 'grad_norm': 1.6398965120315552, 'learning_rate': 1.45e-05, 'epoch': 0.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6000/20000 [11:53<28:12,  8.27it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.8516, 'grad_norm': 1.6790838241577148, 'learning_rate': 1.4e-05, 'epoch': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▎      | 6500/20000 [12:57<25:21,  8.87it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.83, 'grad_norm': 1.4202677011489868, 'learning_rate': 1.3500000000000001e-05, 'epoch': 0.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7000/20000 [14:02<26:49,  8.08it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.8213, 'grad_norm': 1.6543432474136353, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 7500/20000 [15:05<24:15,  8.59it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.8292, 'grad_norm': 1.3228579759597778, 'learning_rate': 1.25e-05, 'epoch': 0.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8000/20000 [16:09<24:20,  8.21it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.8321, 'grad_norm': 1.5898511409759521, 'learning_rate': 1.2e-05, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▎     | 8500/20000 [17:13<23:34,  8.13it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.8292, 'grad_norm': 1.5531346797943115, 'learning_rate': 1.15e-05, 'epoch': 0.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9000/20000 [18:17<21:36,  8.48it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.8272, 'grad_norm': 20.47517967224121, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 9500/20000 [19:19<23:46,  7.36it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.747, 'grad_norm': 1.5292919874191284, 'learning_rate': 1.0500000000000001e-05, 'epoch': 0.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10000/20000 [20:23<19:46,  8.43it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7048, 'grad_norm': 2.3097357749938965, 'learning_rate': 1e-05, 'epoch': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▎    | 10500/20000 [21:26<19:57,  7.94it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.6875, 'grad_norm': 1.7585214376449585, 'learning_rate': 9.5e-06, 'epoch': 0.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11000/20000 [22:30<19:54,  7.53it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7397, 'grad_norm': 2.354895830154419, 'learning_rate': 9e-06, 'epoch': 0.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▊    | 11500/20000 [23:35<16:44,  8.46it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.6998, 'grad_norm': 1.3287678956985474, 'learning_rate': 8.5e-06, 'epoch': 0.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12000/20000 [24:45<16:26,  8.11it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.6949, 'grad_norm': 1.4378615617752075, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 12500/20000 [25:49<15:13,  8.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7473, 'grad_norm': 1.2518507242202759, 'learning_rate': 7.500000000000001e-06, 'epoch': 0.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13000/20000 [26:55<14:58,  7.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7518, 'grad_norm': 1.6183439493179321, 'learning_rate': 7e-06, 'epoch': 0.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 13500/20000 [27:57<09:16, 11.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7692, 'grad_norm': 2.37007737159729, 'learning_rate': 6.5000000000000004e-06, 'epoch': 0.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14000/20000 [28:43<08:02, 12.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7156, 'grad_norm': 1.486019253730774, 'learning_rate': 6e-06, 'epoch': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▎  | 14500/20000 [29:34<10:26,  8.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.6981, 'grad_norm': 1.6424555778503418, 'learning_rate': 5.500000000000001e-06, 'epoch': 0.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 15000/20000 [30:34<10:16,  8.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.6521, 'grad_norm': 1.336819052696228, 'learning_rate': 5e-06, 'epoch': 0.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 15500/20000 [31:38<10:38,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7102, 'grad_norm': 1.216973066329956, 'learning_rate': 4.5e-06, 'epoch': 0.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16000/20000 [32:41<07:44,  8.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.6814, 'grad_norm': 1.4576952457427979, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▎ | 16500/20000 [33:45<07:03,  8.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.6985, 'grad_norm': 2.013728380203247, 'learning_rate': 3.5e-06, 'epoch': 0.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17000/20000 [34:46<05:42,  8.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.6978, 'grad_norm': 1.3564995527267456, 'learning_rate': 3e-06, 'epoch': 0.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 17500/20000 [35:42<05:21,  7.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7174, 'grad_norm': 1.5112947225570679, 'learning_rate': 2.5e-06, 'epoch': 0.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18000/20000 [36:45<04:05,  8.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.6806, 'grad_norm': 1.0031285285949707, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▎| 18500/20000 [37:48<02:57,  8.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7106, 'grad_norm': 1.5550588369369507, 'learning_rate': 1.5e-06, 'epoch': 0.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 19000/20000 [38:50<01:19, 12.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.688, 'grad_norm': 1.7855503559112549, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 19500/20000 [39:55<01:10,  7.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.6389, 'grad_norm': 1.6744649410247803, 'learning_rate': 5.000000000000001e-07, 'epoch': 0.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [40:56<00:00,  8.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.68, 'grad_norm': 3.0691440105438232, 'learning_rate': 0.0, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "100%|██████████| 20000/20000 [43:20<00:00,  7.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.4760866165161133, 'eval_runtime': 142.2416, 'eval_samples_per_second': 140.606, 'eval_steps_per_second': 35.151, 'epoch': 1.0}\n",
      "{'train_runtime': 2600.3355, 'train_samples_per_second': 30.765, 'train_steps_per_second': 7.691, 'train_loss': 2.8542715698242187, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=20000, training_loss=2.8542715698242187, metrics={'train_runtime': 2600.3355, 'train_samples_per_second': 30.765, 'train_steps_per_second': 7.691, 'total_flos': 2706836029440000.0, 'train_loss': 2.8542715698242187, 'epoch': 1.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Modeli yükleyin\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('t5-small')\n",
    "\n",
    "# Eğitim argümanlarını tanımlayın\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = \"/results/\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "# Trainer'ı oluşturun\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_dict['train'],\n",
    "    eval_dataset=dataset_dict['test'],\n",
    ")\n",
    "\n",
    "# Modeli eğitin\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(\"cpu\")\n",
    "# Örnek giriş\n",
    "input_text = \"I have a headache and I do not feel very good. Please explain doctor.\"\n",
    "\n",
    "# Tokenize edin\n",
    "inputs = tokenizer(input_text, return_tensors='pt', padding=True, truncation=True, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated response: Hello,Thanks for using healthcare magic.I have gone through your query and I can understand what you are saying about the symptoms of a headache which is not very good or that it may be due to an allergic reaction from another person in this case as well but there will also need some help with these problems like anxiety disorder (emotional pain), depression etc...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Modeli değerlendirme moduna alın\n",
    "model.eval()\n",
    "\n",
    "# Yanıt üretin\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs['input_ids'],\n",
    "        attention_mask=inputs['attention_mask'],\n",
    "        max_length=512,       # Maksimum yanıt uzunluğu\n",
    "        num_beams=2,          # Beam search\n",
    "        early_stopping=True,  # Erken durdurma\n",
    "        no_repeat_ngram_size=1 # Tekrarları önlemek için\n",
    "    )\n",
    "\n",
    "# Yanıtı decode edin\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(f\"Generated response: {generated_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Chatbot/Python/Models/Models_local/local_medical_assistant_model\\\\tokenizer_config.json',\n",
       " 'Chatbot/Python/Models/Models_local/local_medical_assistant_model\\\\special_tokens_map.json',\n",
       " 'Chatbot/Python/Models/Models_local/local_medical_assistant_model\\\\tokenizer.json')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained('Chatbot/Python/Models/Models_local/local_medical_assistant_model')\n",
    "tokenizer.save_pretrained('Chatbot/Python/Models/Models_local/local_medical_assistant_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML-DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
